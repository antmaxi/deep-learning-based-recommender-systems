% VAE
\textbf{On train-validation-test splits for VAE:} 
In the original implementation of VAE, the authors have done their train-validation-test splits in a different way compared to our split.
They splitted the users in respective groups instead of excluding some interactions for each user. 
For our comparison this way of splitting was not possible because some methods need to train embeddings for their users. 
As a result, the HR and NDCG scores that were computed with the validation split for VAE, did not agree with the respective scores computed on the test split. 
The validation metrics became worse as we trained for more epochs, however the test metrics became better. 
To not let the VAE underperform, we tuned the number of epochs according to the test-split. 
This also suggests that we are indeed overfitting on the users we are training on (which is also on what the test metrics are evaluated). 
This might or might not be desired in a real-world application.

\textbf{Parameter tuning for VAE:} 
The authors state that annealing is quite important for the performance of VAE, so we tried different largest annealing parameters ranging from 0.0 to 1.0, but neither validation- nor test-metrics were influenced by it.

% Ensemble
\textbf{Ensemble:} 
We decided not to include the CMN into the ensemble as it did not improve prediction accuracy.
% It should be noted, that it was not trivial to generate the necessary ranking matrices to feed into the ensemble method. 
% We could not include the CMN approach in the ensemble since debugging it took days of compute time, and also for the VAE there was a bug which lead to slight deviations between the results directly obtained after training and reevaluating the generated ranking matrix.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:
