%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:

%%% NCF
The NCF methods, namely GMF, MLP, and NeuMF, although relatively simple, seem to yield satisfactory results for all datasets, compared to the other approaches. 
In fact, for Movielens, the GMF and NeuMF methods lead to quite high HR and NDCG scores, that are only surpassed by the ensemble approach.
For Jester, they all yield very good results not very different from the other methods.
For Epinions, MLP and NeuMF seem to achieve the highest scores.
We need to mention that all of the NCF approaches required nearly 20 to 40 minutes to train, and that the most effective updates occur in the first 10 epochs (similar to what the authors state).

%%% CMN

%%% NGCF
The NGCF approach shows itself, among the other assessed methods, as the best on the Jester dataset, performs very well on Movielens, but seems to be the worst on the Epinions dataset.
This could be explained with the difference in the density of these datasets.
In fact, Epinions is very sparse, and probably, it's hard for NGCF to incorporate the collaborative signal into the embeddings in these circumstances.
Moreover, training takes from about an hour (Jester and Epinions) to 6 hours (Movielens), that is, in general, worse than other methods.

%%% VAE
The VAE performed pretty well compared to the other methods on all tested datasets. 
Only on Epinions it falls a bit short. 
One of it's main strengths is certainly that even on a i7-3615QM quad-core CPU with 8GB of RAM it could be trained and evaluated in minutes on Movielens and Jester, and in about an hour on Epinions.

%%% Ensemble
Combining different CF methods experimentally seems to work since the ensemble approach managed to achieve the best scores on the Movielens as well as Jester datasets. 
A little experimenting on the subsets of the methods showed that the increased scores mainly  come from combining the VAE with one of the other methods. 
This suggests that the VAE indeed finds different interesting relationships in the data than the other methods. 
However, combining methods at such a high level like we did also bears problems, mainly the performance and flexibility will be dictated by the slowest and least flexible method in the ensemble. 
The decrease (compared to the individual methods) on the Epinions dataset might be related to the fact that our individual methods already perform pretty poorly. 
Maybe a certain performance threshold on the individual methods is necessary for the ensemble method to have increased performance.

%%%% 
The fact that the CMN took 24h in order to compute three epochs (GeForce GTX 1080 Ti) for the Jester data set can most likely be contributed to the density of the data set as well as the computational complexity of the method $\bigO\left(d\abs{N}(\idxi)+d^2+d\right)\propto\abs{N(\idxi)}$.
<<<<<<< HEAD
Also it seems to be logic that the attention mechanism needs a lot of training interactions in order to perform well, which can be seen by the improved accuracy on the Movielens dataset.
One thing that has to be mentioned is that we could not reproduce the same results as the original paper neither on our epinions data split nor on the original data (as the epinions data was missing).
=======
Also is seems to be logic that the attention mechanism needs a lot of training interactions in order to perform well, which can be seen by the improved accuracy of the Movielens data set.
One thing that has to be mentioned is that we could not reproduce the same results as the original paper neither on our Epinions data split nor on the original data (as the Epinions data was missing).
>>>>>>> aeb861af1771c3b942c87a0b86ffb51074b732a6
