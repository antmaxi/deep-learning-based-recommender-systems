\textbf{TODO: }
\textit{Here we will make comments on the results that were presented in the previous section, as well as on the advantages and limitations of the methods.}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:

%%% NCF

%%% CMN

%%% NGCF
NGCF shows itself among other assessed methods as the best on the Jester dataset 
and as very good on the Movielens, but as the worst on the Epinions dataset.
It could be explained with differences in density of these datasets, because
Epinions is very sparse and, probably, it's hard for NGCF to incorporate 
collaborative signal into embeddings in these circumstances.

%%% VAE


%%% Ensemble
Combining different collaborative filtering methods empirically seems to work as the Ensemble managed to achieve the best scores on the Movielens- and Jester datasets. A little experimenting on the subsets of the methods showed that the increased scores mainly come from combining the variational autoencoder with one of the other methods. This suggests that the variational autoencoder indeed finds different interesting realtionships in the data than the other methods. However, combining methods at such a high level like we did also bears problems, mainly the performance and flexibility will be dictated by the slowest and least flexibel method in the Ensemble. The decrease (compared to the individual methods) on the Epinions dataset might be realted to the fact that our individual methods already perform pretty poorly. Maybe a certain performance threshold on the individual methods is necessary for the Ensemble to have increased performance.
